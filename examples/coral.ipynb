{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "src_path = Path().resolve().parent / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "from preprocessing import Preprocessing\n",
    "from inference import Inference, get_pred_indexes\n",
    "from report import PDFGenerator, postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORAL - Unannotated dataset\n",
    "\n",
    "The format is supported by default by the preprocessing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor = Preprocessing(\"../data/curated-oncology-reports/1.0/coral/unannotated/data/breastca_unannotated.csv\", note_text_column=\"note_text\")\n",
    "preprocessor = Preprocessing(\"../data/curated-oncology-reports/1.0/coral/unannotated/data/pdac_unannotated.csv\", note_text_column=\"note_text\")\n",
    "df = preprocessor.get_processed_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORAL - Annotated dataset\n",
    "\n",
    "You can also manually import the data if your format differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def extract_annotations(folder_path):\n",
    "    \"\"\"\n",
    "    Extract information from .ann and .txt files and store it in a DataFrame.\n",
    "\n",
    "    :param folder_path: Path to the folder containing .ann and .txt files.\n",
    "    :return: DataFrame with columns note, RCH_start_gt, RCH_end_gt, AP_start_gt, AP_end_gt.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Process only .ann files\n",
    "        if filename.endswith(\".ann\"):\n",
    "            file_number = os.path.splitext(filename)[0]  # Get the file number (e.g., 20 from 20.ann)\n",
    "            txt_file = os.path.join(folder_path, f\"{file_number}.txt\")\n",
    "            ann_file = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Read the note from the .txt file\n",
    "            with open(txt_file, \"r\") as txt_f:\n",
    "                note = txt_f.read().strip()\n",
    "\n",
    "            # Initialize variables for the annotations\n",
    "            RCH_start_gt, RCH_end_gt, AP_start_gt, AP_end_gt = None, None, None, None\n",
    "\n",
    "            # Parse the .ann file\n",
    "            with open(ann_file, \"r\") as ann_f:\n",
    "                for line in ann_f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 4:\n",
    "                        tag, label, start, end = parts[0], parts[1], parts[2], parts[3]\n",
    "                        if label == \"hpi_start\":\n",
    "                            RCH_start_gt = int(start)\n",
    "                        elif label == \"hpi_end\":\n",
    "                            RCH_end_gt = int(end)\n",
    "                        elif label == \"ap_start\":\n",
    "                            AP_start_gt = int(start)\n",
    "                        elif label == \"ap_end\":\n",
    "                            AP_end_gt = int(end)\n",
    "\n",
    "            # Append the extracted data\n",
    "            data.append({\n",
    "                \"file_number\": file_number,\n",
    "                \"note\": note,\n",
    "                \"RCH_start_gt\": RCH_start_gt,\n",
    "                \"RCH_end_gt\": RCH_end_gt,\n",
    "                \"AP_start_gt\": AP_start_gt,\n",
    "                \"AP_end_gt\": AP_end_gt,\n",
    "            })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index(\"file_number\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../data/curated-oncology-reports/1.0/coral/annotated/pdac\"\n",
    "# folder_path = \"../data/curated-oncology-reports/1.0/coral/annotated/breastca\"\n",
    "df = extract_annotations(folder_path)\n",
    "df.index = df.index.astype(int)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_engine = Inference(\"../models/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_output = inference_engine.generate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_output = get_pred_indexes(llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llm_output now contains the predicted start and end indexes for both RCH and AP sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing\n",
    "\n",
    "To get the extracted sections a column of strings or a pdf to visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessed_df = postprocessing(llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without ground truth overlay\n",
    "generator = PDFGenerator(llm_output, 'RCH_start_pred', 'RCH_end_pred',\n",
    "                                       'AP_start_pred', 'AP_end_pred')\n",
    "\n",
    "# with ground truth overlay\n",
    "# generator = PDFGenerator(llm_output, 'RCH_start_pred', 'RCH_end_pred',\n",
    "#                                        'AP_start_pred', 'AP_end_pred',\n",
    "#                                        \"RCH_start_gt\", \"RCH_end_gt\",\n",
    "#                                         'AP_start_gt', 'AP_end_gt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessed_df.to_csv(\"../outputs/coral_pred.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sectioning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
